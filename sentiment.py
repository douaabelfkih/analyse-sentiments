import pandas as pd
import numpy as np
import matplotlib
matplotlib.use('Agg')  # Mode non-interactif pour √©viter les blocages
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score
import re
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import pickle
import json
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# T√©l√©charger les ressources NLTK n√©cessaires
try:
    nltk.download('stopwords', quiet=True)
    nltk.download('punkt', quiet=True)
except:
    pass

# ==================== 1. CHARGEMENT DES DONN√âES ====================
def load_data(filepath):
    """Charge le dataset"""
    df = pd.read_csv(filepath)
    print(f"Dataset charg√© : {df.shape[0]} lignes, {df.shape[1]} colonnes")
    return df

# ==================== 2. EXPLORATION DES DONN√âES ====================
def explore_data(df):
    """Affiche des statistiques descriptives"""
    print("\n=== APER√áU DES DONN√âES ===")
    print(df.head())
    
    print("\n=== INFORMATIONS SUR LES COLONNES ===")
    print(df.info())
    
    print("\n=== VALEURS MANQUANTES ===")
    print(df.isnull().sum())
    
    print("\n=== DISTRIBUTION DES SCORES ===")
    print(df['Score'].value_counts().sort_index())
    
    # Visualisation
    plt.figure(figsize=(10, 5))
    
    plt.subplot(1, 2, 1)
    df['Score'].value_counts().sort_index().plot(kind='bar', color='skyblue')
    plt.title('Distribution des Scores')
    plt.xlabel('Score')
    plt.ylabel('Nombre d\'avis')
    
    plt.subplot(1, 2, 2)
    df['Text'].str.len().hist(bins=50, color='coral')
    plt.title('Distribution de la longueur des avis')
    plt.xlabel('Longueur du texte')
    plt.ylabel('Fr√©quence')
    
    plt.tight_layout()
    plt.savefig('exploration_data.png', dpi=100, bbox_inches='tight')
    print("üìä Graphique sauvegard√© : exploration_data.png")
    plt.close()

# ==================== 3. PREPROCESSING ====================
def preprocess_text(text):
    """Nettoie et pr√©traite le texte"""
    if pd.isna(text):
        return ""
    
    # Conversion en minuscules
    text = text.lower()
    
    # Suppression des URLs
    text = re.sub(r'http\S+|www\S+|https\S+', '', text, flags=re.MULTILINE)
    
    # Suppression des mentions et hashtags
    text = re.sub(r'@\w+|#\w+', '', text)
    
    # Suppression des caract√®res sp√©ciaux et chiffres
    text = re.sub(r'[^a-zA-Z\s]', '', text)
    
    # Suppression des espaces multiples
    text = re.sub(r'\s+', ' ', text).strip()
    
    return text

def create_sentiment_label(score, method='binary'):
    """
    Cr√©e les labels de sentiment
    method: 'binary' (positif/n√©gatif), 'ternary' (positif/neutre/n√©gatif), ou 'multiclass' (5 classes)
    """
    if method == 'binary':
        return 1 if score > 3 else 0  # 1=Positif, 0=N√©gatif
    elif method == 'ternary':
        if score <= 2:
            return 0  # N√©gatif
        elif score == 3:
            return 1  # Neutre
        else:
            return 2  # Positif
    else:  # multiclass
        return score - 1  # 0-4 pour classification multiclasse

def prepare_data(df, method='binary', sample_size=None):
    """Pr√©pare les donn√©es pour le mod√®le"""
    # Copie pour √©viter les modifications du dataframe original
    df = df.copy()
    
    # √âchantillonnage si n√©cessaire (pour tests rapides)
    if sample_size:
        df = df.sample(n=min(sample_size, len(df)), random_state=42)
    
    # Suppression des valeurs manquantes
    df = df.dropna(subset=['Text', 'Score'])
    
    # Combinaison du Summary et Text pour plus d'information
    df['combined_text'] = df['Summary'].fillna('') + ' ' + df['Text'].fillna('')
    
    # Preprocessing du texte
    print("Preprocessing du texte en cours...")
    df['cleaned_text'] = df['combined_text'].apply(preprocess_text)
    
    # Cr√©ation des labels
    df['sentiment'] = df['Score'].apply(lambda x: create_sentiment_label(x, method))
    
    # Features additionnelles
    df['text_length'] = df['cleaned_text'].str.len()
    df['word_count'] = df['cleaned_text'].str.split().str.len()
    df['helpfulness_ratio'] = df['HelpfulnessNumerator'] / (df['HelpfulnessDenominator'] + 1)
    
    print(f"Donn√©es pr√©par√©es : {len(df)} avis")
    print(f"Distribution des sentiments : \n{df['sentiment'].value_counts()}")
    
    return df

# ==================== 4. CR√âATION DES FEATURES ====================
def create_features(X_train, X_test, max_features=5000):
    """Cr√©e les features TF-IDF"""
    print(f"Cr√©ation des features TF-IDF (max_features={max_features})...")
    
    vectorizer = TfidfVectorizer(
        max_features=max_features,
        ngram_range=(1, 2),  # Unigrammes et bigrammes
        min_df=5,  # Ignore les mots apparaissant dans moins de 5 documents
        max_df=0.8  # Ignore les mots trop fr√©quents
    )
    
    X_train_tfidf = vectorizer.fit_transform(X_train)
    X_test_tfidf = vectorizer.transform(X_test)
    
    print(f"Shape des features : {X_train_tfidf.shape}")
    
    return X_train_tfidf, X_test_tfidf, vectorizer

# ==================== 5. ENTRA√éNEMENT DES MOD√àLES ====================
def train_models(X_train, y_train, X_test, y_test):
    """Entra√Æne plusieurs mod√®les et compare leurs performances"""
    
    models = {
        'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),
        'Naive Bayes': MultinomialNB(),
        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),
        'XGBoost': XGBClassifier(n_estimators=100, random_state=42, eval_metric='logloss')
    }
    
    results = {}
    
    for name, model in models.items():
        print(f"\n{'='*50}")
        print(f"Entra√Ænement : {name}")
        print(f"{'='*50}")
        
        # Entra√Ænement
        model.fit(X_train, y_train)
        
        # Pr√©dictions
        y_pred = model.predict(X_test)
        
        # M√©triques
        accuracy = accuracy_score(y_test, y_pred)
        f1 = f1_score(y_test, y_pred, average='weighted')
        
        results[name] = {
            'model': model,
            'accuracy': accuracy,
            'f1_score': f1,
            'predictions': y_pred
        }
        
        print(f"Accuracy: {accuracy:.4f}")
        print(f"F1-Score: {f1:.4f}")
        print("\nRapport de classification :")
        print(classification_report(y_test, y_pred))
    
    return results

# ==================== 6. VISUALISATION DES R√âSULTATS ====================
def visualize_results(results, y_test):
    """Visualise les performances des mod√®les"""
    
    # Comparaison des mod√®les
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    
    # Graphique des accuracies
    models_names = list(results.keys())
    accuracies = [results[name]['accuracy'] for name in models_names]
    f1_scores = [results[name]['f1_score'] for name in models_names]
    
    axes[0, 0].bar(models_names, accuracies, color='skyblue')
    axes[0, 0].set_title('Accuracy par mod√®le')
    axes[0, 0].set_ylabel('Accuracy')
    axes[0, 0].tick_params(axis='x', rotation=45)
    
    axes[0, 1].bar(models_names, f1_scores, color='coral')
    axes[0, 1].set_title('F1-Score par mod√®le')
    axes[0, 1].set_ylabel('F1-Score')
    axes[0, 1].tick_params(axis='x', rotation=45)
    
    # Matrices de confusion pour les deux meilleurs mod√®les
    best_model_name = max(results.keys(), key=lambda x: results[x]['accuracy'])
    best_predictions = results[best_model_name]['predictions']
    
    cm = confusion_matrix(y_test, best_predictions)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[1, 0])
    axes[1, 0].set_title(f'Matrice de confusion - {best_model_name}')
    axes[1, 0].set_ylabel('Vraie classe')
    axes[1, 0].set_xlabel('Classe pr√©dite')
    
    # Comparaison finale
    comparison_df = pd.DataFrame({
        'Mod√®le': models_names,
        'Accuracy': accuracies,
        'F1-Score': f1_scores
    }).sort_values('Accuracy', ascending=False)
    
    axes[1, 1].axis('tight')
    axes[1, 1].axis('off')
    table = axes[1, 1].table(cellText=comparison_df.values,
                             colLabels=comparison_df.columns,
                             cellLoc='center',
                             loc='center')
    table.auto_set_font_size(False)
    table.set_fontsize(10)
    table.scale(1, 2)
    axes[1, 1].set_title('Comparaison des mod√®les')
    
    plt.tight_layout()
    plt.savefig('model_comparison.png', dpi=100, bbox_inches='tight')
    print("üìä Graphique sauvegard√© : model_comparison.png")
    plt.close()
    
    print(f"\n{'='*50}")
    print(f"MEILLEUR MOD√àLE : {best_model_name}")
    print(f"Accuracy : {results[best_model_name]['accuracy']:.4f}")
    print(f"F1-Score : {results[best_model_name]['f1_score']:.4f}")
    print(f"{'='*50}")
    
    return best_model_name

# ==================== 7. FONCTION DE PR√âDICTION ====================
def predict_sentiment(text, model, vectorizer, method='binary'):
    """Pr√©dit le sentiment d'un nouveau texte"""
    # Preprocessing
    cleaned = preprocess_text(text)
    
    # Vectorisation
    text_tfidf = vectorizer.transform([cleaned])
    
    # Pr√©diction
    prediction = model.predict(text_tfidf)[0]
    proba = model.predict_proba(text_tfidf)[0]
    
    if method == 'binary':
        sentiment = "POSITIF" if prediction == 1 else "N√âGATIF"
        confidence = max(proba) * 100
    elif method == 'ternary':
        sentiments = {0: "N√âGATIF", 1: "NEUTRE", 2: "POSITIF"}
        sentiment = sentiments[prediction]
        confidence = max(proba) * 100
    else:  # multiclass
        sentiment = f"Score {prediction + 1}/5"
        confidence = max(proba) * 100
    
    return sentiment, confidence

# ==================== 8. SAUVEGARDE ET CHARGEMENT ====================
def get_best_existing_model(filepath='models', method='ternary'):
    """R√©cup√®re les informations du meilleur mod√®le existant"""
    import os
    import glob
    
    if not os.path.exists(filepath):
        return None, 0.0
    
    # Chercher tous les fichiers de m√©tadonn√©es pour la m√©thode sp√©cifi√©e
    metadata_files = glob.glob(f"{filepath}/metadata_{method}_*.json")
    
    if not metadata_files:
        return None, 0.0
    
    best_accuracy = 0.0
    best_metadata_path = None
    
    for metadata_path in metadata_files:
        try:
            with open(metadata_path, 'r') as f:
                metadata = json.load(f)
                if metadata['accuracy'] > best_accuracy:
                    best_accuracy = metadata['accuracy']
                    best_metadata_path = metadata_path
        except:
            continue
    
    return best_metadata_path, best_accuracy

def save_model(model, vectorizer, method, results, filepath='models'):
    """Sauvegarde le mod√®le SEULEMENT s'il est meilleur que les pr√©c√©dents"""
    import os
    
    # Cr√©er le dossier models s'il n'existe pas
    if not os.path.exists(filepath):
        os.makedirs(filepath)
    
    # V√©rifier si un meilleur mod√®le existe d√©j√†
    best_metadata_path, best_existing_accuracy = get_best_existing_model(filepath, method)
    current_accuracy = results['accuracy']
    
    print(f"\n{'='*60}")
    print(f"üìä COMPARAISON DES PERFORMANCES")
    print(f"{'='*60}")
    print(f"üÜï Nouveau mod√®le - Accuracy : {current_accuracy:.4f}")
    
    if best_metadata_path:
        print(f"üèÜ Meilleur mod√®le existant - Accuracy : {best_existing_accuracy:.4f}")
        
        if current_accuracy <= best_existing_accuracy:
            print(f"\n‚ùå Le nouveau mod√®le n'est pas meilleur. Sauvegarde annul√©e.")
            print(f"   Diff√©rence : {(best_existing_accuracy - current_accuracy):.4f}")
            print(f"{'='*60}\n")
            return None, None, None
        else:
            print(f"\n‚úÖ Le nouveau mod√®le est MEILLEUR ! Sauvegarde en cours...")
            print(f"   Am√©lioration : +{(current_accuracy - best_existing_accuracy):.4f}")
    else:
        print(f"üìÅ Aucun mod√®le existant. Premier mod√®le sauvegard√©.")
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # Sauvegarder le mod√®le
    model_path = f"{filepath}/best_model_{method}.pkl"
    with open(model_path, 'wb') as f:
        pickle.dump(model, f)
    
    # Sauvegarder le vectorizer
    vectorizer_path = f"{filepath}/best_vectorizer_{method}.pkl"
    with open(vectorizer_path, 'wb') as f:
        pickle.dump(vectorizer, f)
    
    # Sauvegarder les m√©tadonn√©es avec timestamp
    metadata = {
        'method': method,
        'timestamp': timestamp,
        'model_type': type(model).__name__,
        'accuracy': results['accuracy'],
        'f1_score': results['f1_score'],
        'training_date': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    }
    metadata_path = f"{filepath}/metadata_{method}_{timestamp}.json"
    with open(metadata_path, 'w') as f:
        json.dump(metadata, f, indent=4)
    
    # Sauvegarder aussi les m√©tadonn√©es du meilleur mod√®le actuel
    best_metadata_path = f"{filepath}/best_metadata_{method}.json"
    with open(best_metadata_path, 'w') as f:
        json.dump(metadata, f, indent=4)
    
    print(f"\n‚úÖ MOD√àLE SAUVEGARD√â AVEC SUCC√àS")
    print(f"{'='*60}")
    print(f"üìÅ Mod√®le : {model_path}")
    print(f"üìÅ Vectorizer : {vectorizer_path}")
    print(f"üìÅ M√©tadonn√©es : {metadata_path}")
    print(f"üèÜ Type de mod√®le : {type(model).__name__}")
    print(f"üìà Accuracy : {results['accuracy']:.4f}")
    print(f"üìà F1-Score : {results['f1_score']:.4f}")
    print(f"{'='*60}\n")
    
    return model_path, vectorizer_path, metadata_path

def load_model(filepath='models', method='ternary'):
    """Charge le meilleur mod√®le sauvegard√©"""
    import os
    
    model_path = f"{filepath}/best_model_{method}.pkl"
    vectorizer_path = f"{filepath}/best_vectorizer_{method}.pkl"
    metadata_path = f"{filepath}/best_metadata_{method}.json"
    
    if not os.path.exists(model_path) or not os.path.exists(vectorizer_path):
        print(f"‚ùå Aucun mod√®le trouv√© pour la m√©thode '{method}'")
        return None, None
    
    print(f"üìÇ Chargement du meilleur mod√®le ({method})...")
    
    with open(model_path, 'rb') as f:
        model = pickle.load(f)
    
    with open(vectorizer_path, 'rb') as f:
        vectorizer = pickle.load(f)
    
    # Charger les m√©tadonn√©es si disponibles
    if os.path.exists(metadata_path):
        with open(metadata_path, 'r') as f:
            metadata = json.load(f)
        print(f"‚úÖ Mod√®le charg√© : {metadata['model_type']}")
        print(f"üìà Accuracy : {metadata['accuracy']:.4f}")
        print(f"üìà F1-Score : {metadata['f1_score']:.4f}")
        print(f"üìÖ Date d'entra√Ænement : {metadata.get('training_date', 'N/A')}")
    else:
        print("‚úÖ Mod√®le charg√© avec succ√®s!")
    
    return model, vectorizer

# ==================== 9. PIPELINE PRINCIPAL ====================
def main(filepath, method='binary', sample_size=None):
    """
    Pipeline complet d'analyse sentimentale
    
    Parameters:
    - filepath: chemin vers le fichier CSV
    - method: 'binary' (positif/n√©gatif), 'ternary' (positif/neutre/n√©gatif), ou 'multiclass' (5 classes)
    - sample_size: nombre d'√©chantillons (None pour tout le dataset)
    """
    
    # Chargement
    df = load_data(filepath)
    
    # Exploration
    explore_data(df)
    
    # Pr√©paration
    df_processed = prepare_data(df, method=method, sample_size=sample_size)
    
    # Split train/test
    X = df_processed['cleaned_text']
    y = df_processed['sentiment']
    
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    print(f"\nTaille du training set : {len(X_train)}")
    print(f"Taille du test set : {len(X_test)}")
    
    # Cr√©ation des features
    X_train_tfidf, X_test_tfidf, vectorizer = create_features(X_train, X_test)
    
    # Entra√Ænement
    results = train_models(X_train_tfidf, y_train, X_test_tfidf, y_test)
    
    # Visualisation
    best_model_name = visualize_results(results, y_test)
    
    # Retour du meilleur mod√®le et du vectorizer
    best_model = results[best_model_name]['model']
    best_results = {
        'accuracy': results[best_model_name]['accuracy'],
        'f1_score': results[best_model_name]['f1_score']
    }
    
    # Sauvegarde automatique du meilleur mod√®le
    save_model(best_model, vectorizer, method, best_results)
    
    return best_model, vectorizer, results

# ==================== EXEMPLE D'UTILISATION ====================
if __name__ == "__main__":
    # Chemin vers votre fichier CSV
    FILEPATH = "data/Reviews.csv"
    
    print("="*60)
    print("D√âMARRAGE DE L'ANALYSE SENTIMENTALE")
    print("="*60)
    
    # V√©rification que le fichier existe
    import os
    if not os.path.exists(FILEPATH):
        print(f"‚ùå ERREUR : Le fichier {FILEPATH} n'existe pas!")
        print(f"üìÅ Dossier actuel : {os.getcwd()}")
        print(f"üìÑ Fichiers disponibles : {os.listdir('.')}")
        exit(1)
    
    print(f"‚úÖ Fichier trouv√© : {FILEPATH}\n")
    
    # Ex√©cution du pipeline avec classification TERNAIRE (Positif/Neutre/N√©gatif)
    best_model, vectorizer, all_results = main(
        FILEPATH, 
        method='ternary',  # Chang√© de 'binary' √† 'ternary' pour d√©tecter les neutres
        sample_size=50000
    )
    
    # Test de pr√©diction sur de nouveaux textes
    print("\n" + "="*50)
    print("TEST DE PR√âDICTION")
    print("="*50)
    
    test_reviews = [
        "This product is absolutely amazing! Best purchase ever!",
        "Terrible quality. Don't waste your money.",
        "It's okay, nothing special but does the job.",
        "Not bad, meets expectations.",
        "Outstanding product! Highly recommended!"
    ]
    
    for review in test_reviews:
        sentiment, confidence = predict_sentiment(review, best_model, vectorizer, method='ternary')
        print(f"\nAvis : {review}")
        print(f"Sentiment : {sentiment} (Confiance: {confidence:.2f}%)")